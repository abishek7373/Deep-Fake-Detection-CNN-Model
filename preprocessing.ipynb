{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nMI7CYxcyiUB"
   },
   "source": [
    "Before running the file Upload all your data set on your goole drive in a zip format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f4y_fGlmur4v"
   },
   "outputs": [],
   "source": [
    "#before running this please change the RUNTIME to GPU (Runtime -> Change runtime type -> set harware accelarotor as GPU)\n",
    "#download and unzip the data from google drive Colab environment\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "#use only file id of the link\n",
    "#Note: Below link is just an example, Not an actual link. Actual Links are in ReadMe file\n",
    "#https://drive.google.com/file/d/1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07/view?usp=sharing\n",
    "url = '1ubvKLzBDe5i1acxgGUK6ObeNBYCKUS07'\n",
    "gdd.download_file_from_google_drive(file_id = url,dest_path='./data.zip',unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1f40EeRuvAkO"
   },
   "outputs": [],
   "source": [
    "#To get the average frame count \n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "#change the path accordingly\n",
    "video_files =  glob.glob('/content/Real videos/*.mp4')\n",
    "#video_files1 =  glob.glob('/content/dfdc_train_part_0/*.mp4')\n",
    "#video_files += video_files1\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "  cap = cv2.VideoCapture(video_file)\n",
    "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
    "    video_files.remove(video_file)\n",
    "    continue\n",
    "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print(\"frames\" , frame_count)\n",
    "print(\"Total number of videos: \" , len(frame_count))\n",
    "print('Average frame per video:',np.mean(frame_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U92Ovn3JvV52"
   },
   "outputs": [],
   "source": [
    "# to extract frame\n",
    "def frame_extract(path):\n",
    "  vidObj = cv2.VideoCapture(path) \n",
    "  success = 1\n",
    "  while success:\n",
    "      success, image = vidObj.read()\n",
    "      if success:\n",
    "          yield image\n",
    "!pip3 install face_recognition\n",
    "!mkdir '/content/drive/My Drive/FF_REAL_Face_only_data'\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm.autonotebook import tqdm\n",
    "# process the frames\n",
    "def create_face_videos(path_list,out_dir):\n",
    "  already_present_count =  glob.glob(out_dir+'*.mp4')\n",
    "  print(\"No of videos already present \" , len(already_present_count))\n",
    "  for path in tqdm(path_list):\n",
    "    out_path = os.path.join(out_dir,path.split('/')[-1])\n",
    "    file_exists = glob.glob(out_path)\n",
    "    if(len(file_exists) != 0):\n",
    "      print(\"File Already exists: \" , out_path)\n",
    "      continue\n",
    "    frames = []\n",
    "    flag = 0\n",
    "    face_all = []\n",
    "    frames1 = []\n",
    "    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
    "    for idx,frame in enumerate(frame_extract(path)):\n",
    "      #if(idx % 3 == 0):\n",
    "      if(idx <= 150):\n",
    "        frames.append(frame)\n",
    "        if(len(frames) == 4):\n",
    "          faces = face_recognition.batch_face_locations(frames)\n",
    "          for i,face in enumerate(faces):\n",
    "            if(len(face) != 0):\n",
    "              top,right,bottom,left = face[0]\n",
    "            try:\n",
    "              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
    "            except:\n",
    "              pass\n",
    "          frames = []\n",
    "    try:\n",
    "      del top,right,bottom,left\n",
    "    except:\n",
    "      pass\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sF5qiWGLvei-",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm.tqdm import tqdm\n",
    "\n",
    "video_files = glob.glob('C:/Projects/DeepfakeDetection/original_sequences/youtube/c23/videos/005.mp4')\n",
    "\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) < 150:\n",
    "        video_files.remove(video_file)\n",
    "        continue\n",
    "    frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "print(\"Frames:\", frame_count)\n",
    "print(\"Total number of videos:\", len(frame_count))\n",
    "print('Average frame per video:', np.mean(frame_count))\n",
    "\n",
    "# Cell 3: Define a function to extract frames from a video\n",
    "def frame_extract(path):\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            yield image\n",
    "\n",
    "# No need to create a directory if it already exists\n",
    "output_dir = 'C:/Projects/DeepfakeDetection/original_sequences/Fake'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def create_face_videos(path_list, out_dir):\n",
    "    already_present_count = glob.glob(out_dir + '/*.mp4')\n",
    "    print(\"Number of videos already present:\", len(already_present_count))\n",
    "    for path in tqdm(path_list):\n",
    "        out_path = os.path.join(out_dir, path.split('/')[-1])\n",
    "        file_exists = glob.glob(out_path)\n",
    "        if len(file_exists) != 0:\n",
    "            print(\"File Already exists:\", out_path)\n",
    "            continue\n",
    "        frames = []\n",
    "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 30, (112, 112))\n",
    "        for idx, frame in enumerate(frame_extract(path)):\n",
    "            if idx <= 150:\n",
    "                frames.append(frame)\n",
    "                if len(frames) == 4:\n",
    "                    faces = face_recognition.batch_face_locations(frames)\n",
    "                    for i, face in enumerate(faces):\n",
    "                        if len(face) != 0:\n",
    "                            top, right, bottom, left = face[0]\n",
    "                            try:\n",
    "                                out.write(cv2.resize(frames[i][top:bottom, left:right, :], (112, 112)))\n",
    "                            except:\n",
    "                                pass\n",
    "                    frames = []\n",
    "        try:\n",
    "            del top, right, bottom, left\n",
    "        except:\n",
    "            pass\n",
    "        out.release()\n",
    "\n",
    "create_face_videos(video_files, 'C:/Projects/DeepfakeDetection/original_sequences/Fake')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames: [637]\n",
      "Total number of videos: 1\n",
      "Average frame per video: 637.0\n",
      "Number of videos already present: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [03:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 73\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m         out\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m---> 73\u001b[0m \u001b[43mcreate_face_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Projects/DeepfakeDetection/original_sequences/Fake\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 58\u001b[0m, in \u001b[0;36mcreate_face_videos\u001b[1;34m(path_list, out_dir)\u001b[0m\n\u001b[0;32m     56\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(frame)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m---> 58\u001b[0m     faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_recognition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, face \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(faces):\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\face_recognition\\api.py:149\u001b[0m, in \u001b[0;36mbatch_face_locations\u001b[1;34m(images, number_of_times_to_upsample, batch_size)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_cnn_detections_to_css\u001b[39m(detections):\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face\u001b[38;5;241m.\u001b[39mrect), images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m detections]\n\u001b[1;32m--> 149\u001b[0m raw_detections_batched \u001b[38;5;241m=\u001b[39m \u001b[43m_raw_face_locations_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(convert_cnn_detections_to_css, raw_detections_batched))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm import tqdm  # Corrected import\n",
    "\n",
    "video_files = glob.glob('C:/Projects/DeepfakeDetection/original_sequences/youtube/c23/videos/008.mp4')\n",
    "\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) < 150:\n",
    "        video_files.remove(video_file)\n",
    "        continue\n",
    "    frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "print(\"Frames:\", frame_count)\n",
    "print(\"Total number of videos:\", len(frame_count))\n",
    "print('Average frame per video:', np.mean(frame_count))\n",
    "\n",
    "# Define a function to extract frames from a video\n",
    "def frame_extract(path):\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            yield image\n",
    "\n",
    "# No need to create a directory if it already exists\n",
    "output_dir = 'C:/Projects/DeepfakeDetection/original_sequences/Fake'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def create_face_videos(path_list, out_dir):\n",
    "    already_present_count = glob.glob(out_dir + '/*.mp4')\n",
    "    print(\"Number of videos already present:\", len(already_present_count))\n",
    "    for path in tqdm(path_list):\n",
    "        out_path = os.path.join(out_dir, path.split('/')[-1])\n",
    "        file_exists = glob.glob(out_path)\n",
    "        if len(file_exists) != 0:\n",
    "            print(\"File Already exists:\", out_path)\n",
    "            continue\n",
    "        frames = []\n",
    "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 30, (112, 112))\n",
    "        for idx, frame in enumerate(frame_extract(path)):\n",
    "            if idx <= 150:\n",
    "                frames.append(frame)\n",
    "                if len(frames) == 4:\n",
    "                    faces = face_recognition.batch_face_locations(frames)\n",
    "                    for i, face in enumerate(faces):\n",
    "                        if len(face) != 0:\n",
    "                            top, right, bottom, left = face[0]\n",
    "                            try:\n",
    "                                out.write(cv2.resize(frames[i][top:bottom, left:right, :], (112, 112)))\n",
    "                            except:\n",
    "                                pass\n",
    "                    frames = []\n",
    "        try:\n",
    "            del top, right, bottom, left\n",
    "        except:\n",
    "            pass\n",
    "        out.release()\n",
    "\n",
    "create_face_videos(video_files, 'C:/Projects/DeepfakeDetection/original_sequences/Fake')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames: [332]\n",
      "Total number of videos: 1\n",
      "Average frame per video: 332.0\n",
      "Number of videos already present: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 1/1 [1:34:42<00:00, 5682.05s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm import tqdm\n",
    "\n",
    "video_files = glob.glob('C:/Projects/DeepfakeDetection/original_sequences/youtube/c23/videos/013.mp4')\n",
    "\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "    cap = cv2.VideoCapture(video_file)\n",
    "    if int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) < 150:\n",
    "        video_files.remove(video_file)\n",
    "        continue\n",
    "    frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "print(\"Frames:\", frame_count)\n",
    "print(\"Total number of videos:\", len(frame_count))\n",
    "print('Average frame per video:', np.mean(frame_count))\n",
    "\n",
    "# Define a function to extract frames from a video\n",
    "def frame_extract(path):\n",
    "    vidObj = cv2.VideoCapture(path)\n",
    "    success = True\n",
    "    while success:\n",
    "        success, image = vidObj.read()\n",
    "        if success:\n",
    "            yield image\n",
    "\n",
    "# No need to create a directory if it already exists\n",
    "output_dir = 'C:/Projects/DeepfakeDetection/original_sequences/Fake'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def create_face_videos(path_list, out_dir):\n",
    "    already_present_count = glob.glob(out_dir + '/*.mp4')\n",
    "    print(\"Number of videos already present:\", len(already_present_count))\n",
    "    for path in tqdm(path_list):\n",
    "        out_path = os.path.join(out_dir, os.path.basename(path))\n",
    "        file_exists = glob.glob(out_path)\n",
    "        if len(file_exists) != 0:\n",
    "            print(\"File Already exists:\", out_path)\n",
    "            continue\n",
    "        frames = []\n",
    "        out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc('X', 'V', 'I', 'D'), 30, (112, 112))\n",
    "        for idx, frame in enumerate(frame_extract(path)):\n",
    "            if idx <= 150:\n",
    "                frames.append(frame)\n",
    "                if len(frames) == 4:\n",
    "                    faces = face_recognition.batch_face_locations(frames)\n",
    "                    for i, face in enumerate(faces):\n",
    "                        if len(face) != 0:\n",
    "                            top, right, bottom, left = face[0]\n",
    "                            try:\n",
    "                                cropped_face = frames[i][top:bottom, left:right, :]\n",
    "                                resized_face = cv2.resize(cropped_face, (112, 112))\n",
    "                                out.write(resized_face)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing frame {idx} in video {path}: {e}\")\n",
    "                    frames = []\n",
    "        out.release()\n",
    "\n",
    "create_face_videos(video_files, 'C:/Projects/DeepfakeDetection/original_sequences/Fake')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
